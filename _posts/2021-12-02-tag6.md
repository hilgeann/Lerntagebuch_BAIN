---
title: "Tag 6"
date: 2021-12-02
---

Metadaten modellieren und Schnittstellen nutzen I

Nachtrag Lehreinheit 5:
Nun beginne ich meinen Eintrag mal wieder mit einem kleinen Nachtrag zum Thema Persistent Identifier. Im Lerntagebucheintrag zur 5. Veranstaltung habe ich in Zusammenhang mit der langfristigen Auffindbarkeit von Datensätzen die DOIs erwähnt, wozu hier noch ein paar klärende Angaben nötig sind. So ist z.B. DataCite ein Dienst, der für die Registrierung und Verwaltung von DOIs zuständig ist. Sollte sich aber an den Metadaten oder der URL etwas ändern, muss dies z.B. bei DataCite aktualisiert werden. Die DOI ändert sich dadurch aber nicht und das ist das Entscheidende an diesem System.

Dann fange ich hier nun mit dem eigentlichen Eintrag zur LE 6 an. Konkret habe ich mir vorgenommen einen Begriff für mich zu definieren, der mir wohl doch nicht so klar scheint, wie ich dachte. So oft habe ich bereits das Wort «Schnittstelle/n» gehört – gerade auch bei der Arbeit aktuell bzgl. der Anforderungen an das neue LMS in der Kantonsbibliothek BL - und selbst gebraucht und habe nun bemerkt, dass ich über deren Bedeutung und Funktion noch zu wenig weiss. Im Speziellen gehe ich auf OAI-OMH ein. OAI steht also für die Open Archives Initiative und ist eine Initiative von Organisationen, die Server für elektronische Publikationen (wie z. B. Preprints, Postprints) oder andere Dokumentenserver betreiben. Ihre Arbeit konzentriert sich im Wesentlichen auf den freien Zugang zu wissenschaftlichen Publikationen bzw. auf unterschiedliche digitale Ressourcen. Das PMH (Protocol for Metadata Harvesting) ist ein Web-Protokoll, welches die Auffindbarkeit dieser Ressourcen, die sich in verschiedenen Repositorien befinden, mithilfe des Metadatenaustausches zu verbessern, also die Metadaten an Portale und Kataloge weiterzugeben. Statt wie bei der Z39.50 Schnittstelle mehrere Repositorien (Data Provider) bei jeder Suchanfrage zu durchsuchen, sieht das PMH-Konzept vor die Daten der verschiedenen Provider in einem Speicher zusammenzutragen, wo sie dann vom Service Provider (wie z.B. BASE) für die Suche aufbereitet und bereitgestellt, also erschlossen werden. Dieses Konzept bietet den Vorteil bei grossen Abfragen und bietet regelmässige Aktualisierungen. Die Data Provider sind dafür verantwortlich, technisch frei zugängliche Metadatenbeschreibungen zur Verfügung zu stellen. Diese Metadatenbestände werden dann vom Service Provider regelmässig abgefragt, gesammelt und über das Suchinterface zur Verfügung gestellt. Die Metadaten werden in XML codiert, über das http transportiert und mit dem Metadatenstandard Dublin Core beschrieben. Das Zugrunde liegen dieser Standards ist ein Vorteil des OAI-PMH. Ein Kritikpunkt an diesem Konzept ist die Förderung von Datensilos, auf welche nur mithilfe von OAI-PMH zugegriffen werden kann. Ausserdem werden die Metadaten von den Service Providern nicht-selektiert gesammelt. So ist ein Filter z.B. erst in einem weiteren Schritt möglich. Wobei mir das nicht ganz klar ist, was da gemeint ist? Ausserdem habe ich in einer älteren Quelle das Gegenteil gelesen, dass die Service Provider eben selektierte Abfragen machen können.
Dann nutzen wir im Unterricht mit [VuFindHarvest](https://vufind.org/wiki/indexing:oai-pmh) einen wie oben beschriebenen Service Provider, um die Metadaten aus Koha und ArchivesSpace zusammenzutragen, wobei uns die Daten dann «erst» in MARC-XML, EAD und DC vorliegen. Damit usn am Ende alle Daten im Format MARC-XML vorliegen, werden wir einen sogenannten Crosswalk durchführen, der die Konvertierung der Daten von einem Metadatenstandard in einen anderen beschreibt. Wir nutzen dazu XSLT, die Programmiersprache, welche Elemente einer XML-basierten Sprache in eine andere XML-gerechte Sprache transformieren kann. XSLT ist die Transformations-Komponente von XSL. Im XSLT-Stylesheet werden somit Verbindungen hergestellt zwischen dem sogenannten Quellbaum und dem Ergebnisbaum. Ein Beispiel: Man könnte im XSLT-Stylesheet angeben, dass das Element namens «vorname» aus dem Quellcode im Ergeniscode als <td>[...]</td> umgesetzt werden soll. Dieses Mapping kann leider nicht immer völlig verlustfrei geschehen, weil die Quelldaten immer noch manuell erfasst wurden und somit unterschiedliche Handhabe zu Differenzen führen kann.

Verwendete Quellen:

+ <https://zenodo.org/record/1253735/files/Diederichs%20Wuttke%20OAI%20PMH%20Term%20Paper%202018.pdf>
+ <https://www.forschungsdaten.org/index.php/OAI-PMH>
+ <https://wiki.selfhtml.org/wiki/XML/XSL/XSLT>
